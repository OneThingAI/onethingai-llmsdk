package main

import (
	"context"
	"fmt"
	"log"
	"os"

	onethingai "wx-gitlab.xunlei.cn/computing_platform/onethingai-sdk/golang-sdk"
)

var (
	reqModel = "gpt-4o"
)

func main() {
	// Get API key from environment variable or use default
	apiKey := os.Getenv("ONETHINGAI_API_KEY")
	if apiKey == "" {
		// apiKey = "6c5cd6d9f92101f463709726fd2bbebf" // æ­£å¼çŽ¯å¢ƒ API Key
		apiKey = "fd36d0f69b6466e24491d78d80c124d2"
	}

	baseUrl := os.Getenv("ONETHINGAI_BASE_URL")
	if baseUrl == "" {
		// baseUrl = "https://api-model.onethingai.com/v2" // æ­£å¼çŽ¯å¢ƒ URL
		baseUrl = "http://api-model.onethingaidev.com/v2"
	}

	// Create client
	client, err := onethingai.NewClient(apiKey, onethingai.WithBaseURL(baseUrl))
	if err != nil {
		log.Fatalf("Failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()

	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘         OneThing AI - Text Generation Examples           â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println()

	// Example 1: Chat Completion
	if err := example1ChatCompletion(ctx, client); err != nil {
		log.Printf("âŒ Chat completion error: %v\n", err)
	}
	fmt.Println()

	// Example 2: Chat Completion Streaming
	if err := example2ChatCompletionStreaming(ctx, client); err != nil {
		log.Printf("âŒ Chat completion streaming error: %v\n", err)
	}
	fmt.Println()

	// Example 3: Completions
	if err := example3Completions(ctx, client); err != nil {
		log.Printf("âŒ Completions error: %v\n", err)
	}
	fmt.Println()

	// Example 4: Completions Streaming
	if err := example4CompletionsStreaming(ctx, client); err != nil {
		log.Printf("âŒ Completions streaming error: %v\n", err)
	}
	fmt.Println()

	// Example 5: Responses
	if err := example5Responses(ctx, client); err != nil {
		log.Printf("âŒ Responses error: %v\n", err)
	}
	fmt.Println()

	// Example 6: ResponsesStreaming
	if err := example6ResponsesStreaming(ctx, client); err != nil {
		log.Printf("âŒ Responses streaming error: %v\n", err)
	}
	fmt.Println()

	// Example 7: Multi-turn Conversation
	if err := example7MultiTurnConversation(ctx, client); err != nil {
		log.Printf("âŒ Multi-turn conversation error: %v\n", err)
	}
	fmt.Println()

	// Example 7: Generic Text Generation with Custom Parameters
	if err := example7CustomParameters(ctx, client); err != nil {
		log.Printf("âŒ Custom parameters error: %v\n", err)
	}
	fmt.Println()

	// Example 8: Different Temperature Settings
	if err := example8TemperatureVariations(ctx, client); err != nil {
		log.Printf("âŒ Temperature variations error: %v\n", err)
	}
	fmt.Println()

	fmt.Println("âœ… All text generation examples completed!")
}

// Example 1: Basic Chat Completion
func example1ChatCompletion(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸ“ Example 1: Basic Chat Completion")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model": reqModel,
		"messages": []map[string]interface{}{
			{
				"role":    "system",
				"content": "You are a helpful AI assistant.",
			},
			{
				"role":    "user",
				"content": "Explain quantum computing in one sentence.",
			},
		},
		"max_tokens":  100,
		"temperature": 0.7,
	}

	response, err := client.ChatCompletion(ctx, request)
	if err != nil {
		return fmt.Errorf("chat completion failed: %w", err)
	}

	fmt.Printf("âœ“ Request ID: %s\n", response.RequestID)
	fmt.Printf("âœ“ Response Code: %d\n", response.Code)

	if choices, ok := response.Data["choices"].([]interface{}); ok && len(choices) > 0 {
		if choice, ok := choices[0].(map[string]interface{}); ok {
			if message, ok := choice["message"].(map[string]interface{}); ok {
				if content, ok := message["content"].(string); ok {
					fmt.Printf("\nðŸ’¬ Assistant: %s\n", content)
				}
			}
		}
	}

	return nil
}

// Example 2: Streaming Chat Completion
func example2ChatCompletionStreaming(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸŒŠ Example 2: Streaming Chat Completion")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model": reqModel,
		"messages": []map[string]interface{}{
			{
				"role":    "user",
				"content": "Write a short poem about AI.",
			},
		},
		"max_tokens":  150,
		"temperature": 0.8,
	}

	reader, err := client.ChatCompletionStreaming(ctx, request)
	if err != nil {
		return fmt.Errorf("streaming failed: %w", err)
	}
	defer reader.Close()

	fmt.Print("\nðŸ’¬ Assistant: ")

	for {
		chunk, err := reader.Next()
		if err != nil {
			break // EOF or error
		}

		if choices, ok := chunk["choices"].([]interface{}); ok && len(choices) > 0 {
			if choice, ok := choices[0].(map[string]interface{}); ok {
				if delta, ok := choice["delta"].(map[string]interface{}); ok {
					if content, ok := delta["content"].(string); ok {
						fmt.Print(content)
					}
				}
			}
		}
	}

	fmt.Println("\n\nâœ“ Streaming completed!")
	return nil
}

// Example 3: Text Completions
func example3Completions(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸ“„ Example 3: Text Completions")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model":       reqModel,
		"prompt":      "The future of artificial intelligence is",
		"max_tokens":  100,
		"temperature": 0.7,
	}

	response, err := client.Completions(ctx, request)
	if err != nil {
		return fmt.Errorf("completions failed: %w", err)
	}

	fmt.Printf("âœ“ Request ID: %s\n", response.RequestID)

	if choices, ok := response.Data["choices"].([]interface{}); ok && len(choices) > 0 {
		if choice, ok := choices[0].(map[string]interface{}); ok {
			var text string
			if t, ok := choice["text"].(string); ok {
				text = t
			} else if message, ok := choice["message"].(map[string]interface{}); ok {
				if content, ok := message["content"].(string); ok {
					text = content
				}
			}
			fmt.Printf("\nðŸ“ Completed: %s\n", text)
		}
	}

	return nil
}

// Example 4: Completions Streaming
func example4CompletionsStreaming(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸŒŠ Example 4: Completions Streaming")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model":       reqModel,
		"prompt":      "Once upon a time in a digital world,",
		"max_tokens":  150,
		"temperature": 0.9,
	}

	reader, err := client.CompletionsStreaming(ctx, request)
	if err != nil {
		return fmt.Errorf("streaming completions failed: %w", err)
	}
	defer reader.Close()

	fmt.Print("\nðŸ“– Story: ")

	for {
		chunk, err := reader.Next()
		if err != nil {
			break
		}

		if choices, ok := chunk["choices"].([]interface{}); ok && len(choices) > 0 {
			if choice, ok := choices[0].(map[string]interface{}); ok {
				if delta, ok := choice["delta"].(map[string]interface{}); ok {
					if content, ok := delta["content"].(string); ok {
						fmt.Print(content)
					}
				}
			}
		}
	}

	fmt.Println("\n\nâœ“ Story generation completed!")
	return nil
}

// Example 5: Responses
func example5Responses(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸ’¡ Example 5: Responses")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model": reqModel,
		"input": "What are the benefits of renewable energy?",
	}

	response, err := client.Responses(ctx, request)
	if err != nil {
		return fmt.Errorf("responses failed: %w", err)
	}

	fmt.Printf("âœ“ Request ID: %s\n", response.RequestID)
	log.Printf("Response:%v", response.Data)

	if choices, ok := response.Data["choices"].([]interface{}); ok && len(choices) > 0 {
		if choice, ok := choices[0].(map[string]interface{}); ok {
			var text string
			if t, ok := choice["text"].(string); ok {
				text = t
			} else if message, ok := choice["message"].(map[string]interface{}); ok {
				if content, ok := message["content"].(string); ok {
					text = content
				}
			}
			fmt.Printf("\nðŸ’­ Response: %s\n", text)
		}
	}

	return nil
}

func example6ResponsesStreaming(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸŒŠ Example 6: Responses Streaming")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model": reqModel,
		"input": "What are the benefits of renewable energy?",
	}

	reader, err := client.ResponsesStreaming(ctx, request)
	if err != nil {
		return fmt.Errorf("streaming responses failed: %w", err)
	}
	defer reader.Close()

	fmt.Print("\nðŸ“– Story: ")

	for {
		chunk, err := reader.Next()
		if err != nil {
			break
		}

		log.Printf("Chunk:%v", chunk)

	}

	return nil
}

// Example 7: Multi-turn Conversation
func example7MultiTurnConversation(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸ’¬ Example 7: Multi-turn Conversation")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	// Simulate a conversation history
	messages := []map[string]interface{}{
		{
			"role":    "system",
			"content": "You are a helpful programming tutor.",
		},
		{
			"role":    "user",
			"content": "What is recursion?",
		},
		{
			"role":    "assistant",
			"content": "Recursion is when a function calls itself to solve a problem by breaking it down into smaller subproblems.",
		},
		{
			"role":    "user",
			"content": "Can you give me a simple example in Python?",
		},
	}

	request := map[string]interface{}{
		"model":       reqModel,
		"messages":    messages,
		"max_tokens":  200,
		"temperature": 0.7,
	}

	response, err := client.ChatCompletion(ctx, request)
	if err != nil {
		return fmt.Errorf("multi-turn conversation failed: %w", err)
	}

	fmt.Println("ðŸ“š Conversation Context:")
	for i, msg := range messages {
		role := msg["role"].(string)
		content := msg["content"].(string)
		if role == "system" {
			fmt.Printf("  [System] %s\n", content)
		} else if role == "user" {
			fmt.Printf("  ðŸ‘¤ User: %s\n", content)
		} else {
			fmt.Printf("  ðŸ¤– Assistant: %s\n", content)
		}
		if i < len(messages)-1 {
			fmt.Println()
		}
	}

	if choices, ok := response.Data["choices"].([]interface{}); ok && len(choices) > 0 {
		if choice, ok := choices[0].(map[string]interface{}); ok {
			if message, ok := choice["message"].(map[string]interface{}); ok {
				if content, ok := message["content"].(string); ok {
					fmt.Printf("\nðŸ¤– Assistant: %s\n", content)
				}
			}
		}
	}

	return nil
}

// Example 7: Generic Text Generation with Custom Parameters
func example7CustomParameters(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("âš™ï¸  Example 7: Custom Parameters")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	request := map[string]interface{}{
		"model":    reqModel,
		"job_type": onethingai.TextJobTypeChatCompletions,
		"messages": []map[string]interface{}{
			{
				"role":    "user",
				"content": "Write a creative product name for a smart coffee maker.",
			},
		},
		"max_tokens":        50,
		"temperature":       1.0, // High creativity
		"top_p":             0.9,
		"frequency_penalty": 0.5,
		"presence_penalty":  0.5,
	}

	response, err := client.GenerateText(ctx, request)
	if err != nil {
		return fmt.Errorf("custom parameters generation failed: %w", err)
	}

	fmt.Println("âš™ï¸  Custom Parameters:")
	fmt.Printf("  â€¢ Temperature: %.1f (high creativity)\n", request["temperature"])
	fmt.Printf("  â€¢ Top P: %.1f\n", request["top_p"])
	fmt.Printf("  â€¢ Frequency Penalty: %.1f\n", request["frequency_penalty"])
	fmt.Printf("  â€¢ Presence Penalty: %.1f\n", request["presence_penalty"])

	if choices, ok := response.Data["choices"].([]interface{}); ok && len(choices) > 0 {
		if choice, ok := choices[0].(map[string]interface{}); ok {
			if message, ok := choice["message"].(map[string]interface{}); ok {
				if content, ok := message["content"].(string); ok {
					fmt.Printf("\nðŸ’¡ Generated Name: %s\n", content)
				}
			}
		}
	}

	return nil
}

// Example 8: Different Temperature Settings
func example8TemperatureVariations(ctx context.Context, client *onethingai.Client) error {
	fmt.Println("ðŸŒ¡ï¸  Example 8: Temperature Variations")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	prompt := "Describe the color blue in one sentence."
	temperatures := []float64{0.2, 0.7, 1.2}

	for i, temp := range temperatures {
		fmt.Printf("\nðŸŒ¡ï¸  Temperature: %.1f\n", temp)

		request := map[string]interface{}{
			"model": reqModel,
			"messages": []map[string]interface{}{
				{
					"role":    "user",
					"content": prompt,
				},
			},
			"max_tokens":  60,
			"temperature": temp,
		}

		response, err := client.ChatCompletion(ctx, request)
		if err != nil {
			log.Printf("Temperature %.1f failed: %v", temp, err)
			continue
		}

		if choices, ok := response.Data["choices"].([]interface{}); ok && len(choices) > 0 {
			if choice, ok := choices[0].(map[string]interface{}); ok {
				if message, ok := choice["message"].(map[string]interface{}); ok {
					if content, ok := message["content"].(string); ok {
						fmt.Printf("ðŸ’­ Response: %s\n", content)
					}
				}
			}
		}

		if i < len(temperatures)-1 {
			fmt.Println()
		}
	}

	fmt.Println("\nâœ“ Temperature comparison completed!")
	return nil
}
